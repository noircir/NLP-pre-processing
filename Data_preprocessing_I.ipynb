{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Word docx files into text files\n",
    "\n",
    "This process starts from raw initial Word documents in the /source directory.\n",
    "\n",
    "It renames them to uniform UUID names (still Word files) and saves in the /docs directory.\n",
    "\n",
    "Lastly, it extracts text from Word files and saves text files in /training_data directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Give Word documents unique UUID names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking installed Python versions and executable Python.\n",
    "\n",
    "# import sys\n",
    "# print(sys.path)\n",
    "# print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install docx2txt package where your executable Python is (sys.executable). \n",
    "# Ex:\n",
    "#!~/anaconda3/bin/python -m pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS CELL ONLY IF STARTING FROM ORIGINAL DOWNLOADED WORD DOCUMENTS. \n",
    "# It renames the raw source Word documents and places them into the \"docs\" directory. \n",
    "\n",
    "# NOTE: some files may be zipped; unzip them first in their directory.  \n",
    "\n",
    "sourceDir = \"source\"\n",
    "targetDir = \"docs\"\n",
    "\n",
    "source_directory = os.path.join(os.getcwd(), sourceDir)\n",
    "\n",
    "# if target directory does not already exist, create it\n",
    "if not os.path.exists(targetDir):\n",
    "    \n",
    "    os.mkdir(targetDir)\n",
    "    print(\"Directory '\" + targetDir +  \"' created \")\n",
    "else:    \n",
    "    print(\"Directory '\" + targetDir +  \"' already exists\")\n",
    "    \n",
    "docs_directory = os.path.join(os.getcwd(), targetDir)\n",
    "\n",
    "    \n",
    "for foldername in os.listdir(source_directory):\n",
    "    \n",
    "    # Skip hidden \".DS_Store\" files in MacOS\n",
    "    if foldername[0] != \".\":  \n",
    "        \n",
    "        # read subdirectory\n",
    "        subdirectory = os.path.join(os.getcwd(), \"source\", foldername)\n",
    "        \n",
    "        # for each file in subdirectory\n",
    "        for filename in os.listdir(subdirectory):\n",
    "            \n",
    "            # skip hidden files\n",
    "            if filename[0] != \".\":\n",
    "                \n",
    "                # extract file name and extension\n",
    "                file, extension = os.path.splitext(filename)\n",
    "                # replace file name with uuid-name \n",
    "                unique_filename = str(uuid.uuid4()) + extension\n",
    "                # rename original file with uuid-name and place into 'docs' directory\n",
    "                os.rename(os.path.join(subdirectory,  filename), os.path.join(docs_directory, unique_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in 'docs' directory: 66\n"
     ]
    }
   ],
   "source": [
    "# Show how many files the \"word_docs\" directory contains\n",
    "\n",
    "count = 0\n",
    "source_directory = os.path.join(os.getcwd(), \"docs\")\n",
    "\n",
    "for filename in os.listdir(source_directory):\n",
    "    count += 1\n",
    "print(f\"Number of files in 'docs' directory: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract text from Word documents and create text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4cef2dd2-5098-432b-8d09-c0eaf49d595c.txt\n",
      "30d3574a-6595-40f0-8a9e-112683093dfb.txt\n",
      "80a7bf44-f784-4974-8452-d5116aa1e05b.txt\n",
      "f8759e6f-7f18-48ec-a150-bd93c099f6e0.txt\n",
      "ebbf2db5-89a4-48c8-b999-38d35dd3b24c.txt\n",
      "dba09d88-146b-44cc-a752-c52864dddfec.txt\n",
      "a35fff6e-045c-4bae-9591-b76f4106a925.txt\n",
      "e9c216b6-c032-42e8-a530-ffd69380692f.txt\n",
      "a9b60385-9f4e-483e-93f1-708ffe89979e.txt\n",
      "c9b7489d-3be7-4842-95de-2dad82e07910.txt\n",
      "ef12a989-b456-484a-aee2-2f22a39f864c.txt\n",
      "1c901de2-b287-4b30-b800-8aeb6f531660.txt\n",
      "01c63248-e322-4ca1-96e7-ce89c5d35c92.txt\n",
      "5c4f65e6-9091-41bc-a79b-39eed3fc4dfb.txt\n",
      "9d8090d6-4d89-4eb9-a19f-a637a613ba60.txt\n",
      "1af79ed5-f86b-47a4-9809-88e15d819160.txt\n",
      "86598fd6-59cd-4935-8a78-efcb6c5f9c03.txt\n",
      "8e9690fd-6b5b-408d-b5e0-e37de027fedf.txt\n",
      "4618bc72-4311-43c2-93bc-036a85f6b9f8.txt\n",
      "408df2ab-14b0-49c1-8bbd-16444bb48c01.txt\n",
      "f4236ab4-f5b5-4105-8a04-a66ecc27e3ef.txt\n",
      "36cdb423-f862-437c-b433-6a96aac291ac.txt\n",
      "121a00be-40e3-404d-abab-8265cb7a1395.txt\n",
      "43ea25ea-9c29-4f7d-a0b3-e71d8c790832.txt\n",
      "6ad5fdcc-69a4-4b65-9632-0fb95464e524.txt\n",
      "42f8820b-7cca-400d-bd26-3749119c6482.txt\n",
      "cb3d442f-d8e4-4f6a-aae1-eb711e49f142.txt\n",
      "3450ba62-246b-4df4-8d86-95a3cfcf8e9b.txt\n",
      "088a3c58-cfa8-4113-83dc-95142240e381.txt\n",
      "3f4f5e2e-60fb-430e-829d-38af80c404da.txt\n",
      "67ae8b61-dd8c-4bd3-a4b8-2692edba0914.txt\n",
      "afca05dd-0376-44ad-981e-e8134af8a054.txt\n",
      "9b497ac6-2a70-4d1f-bbea-e0ef22cf757f.txt\n",
      "0e65e4ba-eb5c-4d8c-86cb-b6954553ae63.txt\n",
      "74b81571-e4f1-402b-ad1f-5853f7b548b5.txt\n",
      "45331965-483e-4df7-9dd8-9bca38b4c252.txt\n",
      "23f1d8e5-96a6-435d-9f5a-162f54c1247f.txt\n",
      "b57c9050-c911-4aca-9f19-b846a4f9c214.txt\n",
      "358b3cc5-6de0-4008-9cfb-de4d77c6d93b.txt\n",
      "3b4e30d0-ea05-4a64-bfd8-e6924a621047.txt\n",
      "c64129fe-f9d2-48f8-b73a-315927c8c0ba.txt\n",
      "8d8eaae5-a88b-4523-98a3-dc1437a3b928.txt\n",
      "42a5e45f-f2f3-43ea-9be3-f5e38fc2a7ac.txt\n",
      "2f0f657e-048e-48e5-8fb3-eabf4b26209c.txt\n",
      "7d606a1a-8dec-4193-8a80-2bd33f3d4cc2.txt\n",
      "36a79399-ff36-4891-8284-f9c8f8201ccc.txt\n",
      "84b44812-d1bf-450f-a069-c6120002f786.txt\n",
      "a7b18d59-7b50-4ece-949a-8366d6130f32.txt\n",
      "f35bc95b-bcff-483a-bda6-c8c1cbe727fd.txt\n",
      "ad73ef32-3e14-48df-8bf4-a2c51935a033.txt\n",
      "974859a9-632f-4771-8363-c0e66cd07f93.txt\n",
      "81454620-9dfd-4249-8bc7-20360231dfcf.txt\n",
      "95f54b9f-1d9f-485e-b0b0-5d9baf5bb8d8.txt\n",
      "0670c1e5-7d8c-4b67-af67-0968e72faa43.txt\n",
      "b41bc566-b64a-481f-99c5-63a55a5d1ed5.txt\n",
      "4d3f5a33-999e-42c9-b5c5-f5b9e550cad1.txt\n",
      "2310789e-81b6-4061-9bb8-78cb39072a31.txt\n",
      "10fa6230-39bf-4807-bcfd-80e2ed70a465.txt\n",
      "5cae5a09-0d25-4346-b584-dfb07740517f.txt\n",
      "d68680c5-62a2-4561-9639-fc4ee84cddd9.txt\n",
      "e0e1d9a7-559e-436e-8eb8-61ff9dd15042.txt\n",
      "c34388e7-3927-4356-a90f-a5d17d1f0785.txt\n",
      "833a3fe1-2908-4e93-af0c-30d52906f2aa.txt\n",
      "e0264de1-3a8f-44f0-a08b-7f65ed9cdc55.txt\n",
      "0db2faca-1a12-4dca-8a90-379cfa1b82d2.txt\n"
     ]
    }
   ],
   "source": [
    "source_directory = os.path.join(os.getcwd(), \"docs\")\n",
    "\n",
    "training_directory = os.path.join(os.getcwd(), \"training_data\")\n",
    "\n",
    "for process_file in  os.listdir(source_directory):\n",
    "    \n",
    "    if process_file[0] != \".\":\n",
    "        file, _ = os.path.splitext(process_file)\n",
    "\n",
    "        # We create a new text file name by concatenating the .txt extension to file UUID\n",
    "        dest_file_path = file + '.txt'\n",
    "        print(dest_file_path)\n",
    "        \n",
    "        #extract text from the file\n",
    "        content = docx2txt.process(os.path.join(source_directory, process_file))\n",
    "\n",
    "        # We create and open new file and we prepare to write the Binary Data which is represented by the wb - Write Binary\n",
    "        write_text_file = open(os.path.join(training_directory, dest_file_path), \"w+\")\n",
    "\n",
    "        #write the content and close the newly created file\n",
    "        write_text_file.write(content)\n",
    "        write_text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in 'training_data': 66\n"
     ]
    }
   ],
   "source": [
    "# Show how many files the \"training_data\" directory contains\n",
    "\n",
    "count = 0\n",
    "source_directory = os.path.join(os.getcwd(), \"training_data\")\n",
    "\n",
    "for filename in os.listdir(source_directory):\n",
    "    count += 1\n",
    "print(f\"Number of files in 'training_data': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
